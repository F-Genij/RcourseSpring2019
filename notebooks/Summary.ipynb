{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "A. [Getting datasets](#A.-Getting-data)\n",
    "- text files stored locally\n",
    "- text files from a website\n",
    "\n",
    "B. [Cleaning and transforming datasets](#B.-Cleaning-and-transforming-data)\n",
    "- Inspecting the data frame\n",
    "- Selecting a subset of a data frame\n",
    "- Augmenting a data frame with additional columns/rows (or replacing existing columns/rows)\n",
    "- Dealing with missing values\n",
    "- Converting between the wide and long forms of a data frame\n",
    "- Sorting a data frame\n",
    "\n",
    "C. [Exploring and visualizing datasets](#C.-Exploring-and-visualizing)\n",
    "- Summary statistics and frequencies\n",
    "- Scatter plots & regression lines\n",
    "- Histograms & density lines\n",
    "- Boxplots & barplots with error bars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Getting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can come from different sources, e.g.:\n",
    "- text files stored locally (with different extensions, e.g., `.txt` or `.csv`)\n",
    "- text files from a website\n",
    "\n",
    "#### Different functions to read data from file:\n",
    "- `read.table` is the principal and more general means of reading tabular data into R\n",
    "- `read.csv` sets the default separator to a comma, and assumes that the data has a header row\n",
    "- `read.csv2` is its European cousin, using a comma for decimal places and a semicolon as a separator\n",
    "- `read.delim` and `read.delim2` import tab-delimited files with full stops or commas for decimal places, respectively\n",
    "\n",
    "#### Main arguments that you might want to tweak:\n",
    "- `header` are the names of the variables its first line?\n",
    "- `sep` how are the values separated?\n",
    "- `dec` how are the decimals coded? (dots or commas)\n",
    "- `na.strings` how are the missing values coded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of tab delimitated data\n",
    "data <- read.table('~/git/RcourseSpring2019/data/data_taskA.txt')\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of comma delimitated data, with header as first line\n",
    "data <- read.table('~/git/RcourseSpring2019/data/data_wpa4.csv', \n",
    "                   sep=',',\n",
    "                   header=TRUE)\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of ; delimitated data, with header as first line\n",
    "data <- read.table('~/git/RcourseSpring2019/data/student-por.csv',\n",
    "                   sep=';',\n",
    "                   header=TRUE)\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of data from github (remember to get the raw data first):\n",
    "data <- read.csv('https://raw.githubusercontent.com/laurafontanesi/RcourseSpring2019/master/data/matthews_demographics.csv',\n",
    "                 )\n",
    "head(data)\n",
    "\n",
    "# Try out on your own with data from: https://github.com/BuzzFeedNews/zika-data/tree/master/data/parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to first download a file and then load it in R:\n",
    "data_url <- \"http://samplecsvs.s3.amazonaws.com/Sacramentorealestatetransactions.csv\"\n",
    "local_file_location <- \"~/git/RcourseSpring2019/data/Sacramentorealestatetransactions.csv\"\n",
    "\n",
    "download.file(data_url, local_file_location)\n",
    "\n",
    "data <- read.csv(local_file_location)\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Cleaning and transforming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of the task of cleaning data involves manipulating data frames to get them into the desired form:\n",
    "\n",
    "0. Inspecting the data frame\n",
    "1. Selecting a subset of a data frame\n",
    "2. Augmenting a data frame with additional columns/rows (or replacing existing columns/rows)\n",
    "3. Dealing with missing values\n",
    "4. Converting between the wide and long forms of a data frame\n",
    "5. Sorting a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inspecting the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fake data.frame\n",
    "N = 25\n",
    "fake_data <- data.frame(\n",
    "    participant = 1:N,\n",
    "    risk_parameter = round(rgamma(N, 1, 1), 1)\n",
    ")\n",
    "\n",
    "fake_data[fake_data$risk_parameter > 1, \"risk_preference\"] = \"risk_seeking\"\n",
    "fake_data[fake_data$risk_parameter < 1, \"risk_preference\"] = \"risk_avoidant\"\n",
    "fake_data[fake_data$risk_parameter == 1, \"risk_preference\"] = \"risk_neutral\"\n",
    "\n",
    "fake_data$age = round(22 + rnorm(N, -fake_data$risk_parameter, .8))\n",
    "\n",
    "fake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the row and columns names, and the number of rows and columns:\n",
    "dimnames(fake_data)\n",
    "dim(fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Careful that:\n",
    "length(fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect head and tail:\n",
    "head(fake_data)\n",
    "tail(fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(fake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Subsetting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index a specific cell:\n",
    "fake_data[6, \"risk_parameter\"]\n",
    "\n",
    "# or a row:\n",
    "fake_data[6,]\n",
    "\n",
    "# or a column:\n",
    "fake_data[,\"risk_parameter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows based on a logical condition (aka Boolean indexing):\n",
    "fake_data[fake_data$risk_preference == 'risk_avoidant',]\n",
    "\n",
    "fake_data[fake_data$risk_parameter < 1,]\n",
    "\n",
    "# and maybe select only few columns to keep:\n",
    "subset(fake_data, \n",
    "       age >= 22, \n",
    "       select=c('participant', 'age'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get everything apart from the first column:\n",
    "head(fake_data[,-1])\n",
    "\n",
    "# or third column:\n",
    "head(fake_data[,-3])\n",
    "\n",
    "# get specific columns based on the names:\n",
    "columns_to_keep = c('participant', 'age')\n",
    "head(fake_data[,columns_to_keep])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adding columns and rows:\n",
    "The usual form to add a new column is:\n",
    "\n",
    "data.frame.name$column.name <- vector,\n",
    "\n",
    "where the vector is either:\n",
    "- length = number of rows\n",
    "- lenght = 1 (in that case the same value is assigned to every row)\n",
    "- lenght < number of rows, where number of rows is a multiple of length (in that case the vector is repeated until the whole column is filled)\n",
    "\n",
    "Otherwise, you can use `cbind` and `merge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some example data:\n",
    "data <- read.table('~/git/RcourseSpring2019/data/data_taskA.txt')\n",
    "row.names(data) <- NULL\n",
    "head(data)\n",
    "tail(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column:\n",
    "data$RT_sec <- data$RT_msec/1000\n",
    "data$conditionA <- 'difficult'\n",
    "data$conditionB <- c('difficult', 'easy')\n",
    "\n",
    "head(data)\n",
    "\n",
    "tail(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But:\n",
    "data$conditionC <- c('a', 'b', 'c', 'd', 'e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add rows, you simply need to index a \"new line\" (as with adding columns), by either the row number or row name.\n",
    "\n",
    "Otherwise, you can simply use `rbind`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a row with values for specific columns:\n",
    "new_row <- dim(data)[1] + 1\n",
    "new_row\n",
    "\n",
    "data[new_row, c(1, 2)] <- c(50, 'female')\n",
    "\n",
    "tail(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a row with the same value for all columns:\n",
    "new_row <- new_row + 1\n",
    "new_row\n",
    "\n",
    "data[new_row,] <- NA\n",
    "\n",
    "tail(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any row containing missing values:\n",
    "data_noNA <- na.omit(data)\n",
    "\n",
    "tail(data_noNA)\n",
    "\n",
    "nrows_with_NA <- dim(data)[1] - dim(data_noNA)[1]\n",
    "nrows_with_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any row contanining missed participant number:\n",
    "data_noNA_participant <- data[!is.na(data$participant),]\n",
    "\n",
    "tail(data_noNA_participant)\n",
    "\n",
    "nrows_with_NA_participant <- dim(data)[1] - dim(data_noNA_participant)[1]\n",
    "nrows_with_NA_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any column containing missing values (in this case it doesn't make much sense, but might be useful to know):\n",
    "which_NAs <- apply(\n",
    "    X = is.na(data_noNA_participant),\n",
    "    MARGIN = 2,\n",
    "    FUN = sum\n",
    ")\n",
    "\n",
    "data_noNA_participant <- data_noNA_participant[,which_NAs == 0]\n",
    "\n",
    "head(data_noNA_participant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Converting between the wide and long forms of a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data shown before are in the **long** format: repeated measurements from each participants are stored in different rows. This format is relatively common in cognitive psychology, as we often present participants with tasks in which they have to provide multiple responses for the same item/condition.\n",
    "\n",
    "Another common format is the **wide** format: here, participants' repeated responses will be in a single row, and each response is in a separate column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fake data:\n",
    "N = 10\n",
    "mean_score_students = runif(N, 5, 10)\n",
    "fake_data_wide <- data.frame(\n",
    "    student = 1:N,\n",
    "    age = round(rnorm(N, 30, 5)),\n",
    "    score_WPA1 = mean_score_students,\n",
    "    score_WPA2 = mean_score_students*0.9 + rnorm(N, 0, 0.1),\n",
    "    score_WPA3 = mean_score_students*0.5 + rnorm(N, 0, 1),\n",
    "    score_WPA4 = mean_score_students*0.7 + rnorm(N, 0, 0.2)\n",
    ")\n",
    "\n",
    "fake_data_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library reshape2 to easily transform to long format:\n",
    "library(reshape2)\n",
    "fake_data_long <- melt(fake_data_wide, id.vars = \"student\", measure.vars = c(\"score_WPA1\", \"score_WPA2\", \"score_WPA3\", \"score_WPA4\"))\n",
    "\n",
    "# Re-order based on student number:\n",
    "fake_data_long[order(fake_data_long$student),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To go back to wide format, use dcast and acast (see the difference):\n",
    "dcast(\n",
    "    fake_data_long,\n",
    "    student ~ variable\n",
    "     )\n",
    "\n",
    "acast(\n",
    "    fake_data_long,\n",
    "    student ~ variable\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if you just want to have the unique value per participant of 1 variable, e.g., age? \n",
    "\n",
    "# When data is in the wide format:\n",
    "age_df <- aggregate(age ~ student, data = fake_data_wide, FUN=unique)\n",
    "age_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But it's actually the same for long format:\n",
    "age_df <- aggregate(age ~ participant, data = data, FUN=unique)\n",
    "age_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we can use the dplyr package: https://dplyr.tidyverse.org/\n",
    "library(dplyr)\n",
    "\n",
    "grouped_data = group_by(data, participant)\n",
    "\n",
    "mean_performance = summarise(grouped_data, mean_accuracy=mean(accuracy, na.rm=TRUE), mean_rt=mean(RT_sec, na.rm=TRUE), age=unique(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sorting the data frame by value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most usual way to do this is by using the function order:\n",
    "age_df[order(age_df$age),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or you can use the custom function arrange from the plyr library (easier syntax...):\n",
    "\n",
    "library(plyr)\n",
    "\n",
    "arrange(age_df, age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Exploring and visualizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Summary statistics and frequencies\n",
    "2. Scatter plots & regression lines\n",
    "3. Histograms & density lines\n",
    "4. Boxplots & barplots with error bars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Summary statistics and frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- read.csv(local_file_location)\n",
    "head(data)\n",
    "summary(data)\n",
    "dim(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The single functions for the summary statistics above would be:\n",
    "range(data$price)\n",
    "min(data$price)\n",
    "max(data$price)\n",
    "\n",
    "quantile(data$price, c(.25, .5, .75))\n",
    "\n",
    "median(data$price)\n",
    "\n",
    "mean(data$price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR wraps quantile to give the interquartile range (the 75th percentile minus the 25th percentile):\n",
    "IQR(data$price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use with to make the syntax a bit more digestible:\n",
    "with(data, mean(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Careful that:\n",
    "colMeans(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So you should only select numberical variables:\n",
    "colMeans(data[,c('beds', 'baths', 'sq__ft', 'price')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A more general function is apply, that lets you apply any function to either columns or rows of a dataframe:\n",
    "apply(\n",
    "    data[,c('beds', 'baths', 'sq__ft', 'price')],\n",
    "    MARGIN = 2, # 2 is for columns, 1 is for rows\n",
    "    FUN = mean\n",
    ")\n",
    "\n",
    "apply(\n",
    "    data[,c('beds', 'baths', 'sq__ft', 'price')],\n",
    "    MARGIN = 2, # 2 is for columns\n",
    "    FUN = sd\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, for frequencies:\n",
    "table(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you want to select categorical variables:\n",
    "table(data[,c('city', 'type')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also combine cut with bins, to get the frequencies per bin of a certain variable.\n",
    "\n",
    "# For example, we can look how many properties are there depending on the squared meters, in bins of 1000:\n",
    "table(cut(data$sq__ft, seq.int(0, 6000, 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also calculate correlations and covariances:\n",
    "with(data, cor(price, sq__ft))\n",
    "\n",
    "with(data, cov(price, sq__ft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But if you want a correlation or covariance matrix you should use:\n",
    "cor_mat <- round(cor(data[,c('price', 'sq__ft', 'beds', 'baths')]), 2)\n",
    "cor_mat\n",
    "\n",
    "cov_mat <- cov(data[,c('price', 'sq__ft', 'beds', 'baths')])\n",
    "cov_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scatter plots & regression lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=5, repr.plot.height=5) # this is not necessary in RStudio.\n",
    "\n",
    "plot(x = data$sq__ft, \n",
    "     y = data$price, \n",
    "     col = rgb(.1, .1, .1, .3), \n",
    "     pch = 20,\n",
    "     xlab = 'Squared feet',\n",
    "     ylab = 'Price',\n",
    "     bty = 'l'\n",
    "    )\n",
    "\n",
    "abline( # add regression line\n",
    "    lm(price ~ sq__ft, data),\n",
    "    col = 'maroon4',\n",
    "    lw = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From this plot we see that there are a lot of 0 squared feet houses... \n",
    "# this does not seem to be plausible.\n",
    "# Let's fit a regression without these houses.\n",
    "\n",
    "options(repr.plot.width=5, repr.plot.height=5) # this is not necessary in RStudio.\n",
    "\n",
    "plot(x = data$sq__ft, \n",
    "     y = data$price, \n",
    "     col = rgb(0.1, 0.1, 0.1, .3), \n",
    "     pch = 20,\n",
    "     xlab = 'Squared feet',\n",
    "     ylab = 'Price',\n",
    "     bty = 'l'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Model 1:\n",
    "lm_1 <- lm(price ~ sq__ft, data) # calculate the regression model\n",
    "slope_1 <- lm_1$coefficients['sq__ft'] # extract the slope for the label positioning \n",
    "intercept_1 <- lm_1$coefficients['(Intercept)'] # extract the intercept for the label positioning \n",
    "\n",
    "abline( # add regression line\n",
    "    lm_1,\n",
    "    col = 'maroon4',\n",
    "    lw = 2\n",
    ")\n",
    "text(x = max(data$sq__ft)*.9, # add label at the end of the regression line\n",
    "     y = slope_1 * max(data$sq__ft) + intercept_1, \n",
    "     \"Including 0\", \n",
    "     srt=0.2)\n",
    "\n",
    "\n",
    "\n",
    "# Model 2:\n",
    "lm_2 <- lm(price ~ sq__ft, data[data$sq__ft > 0,]) # calculate the regression model\n",
    "slope_2 <- lm_2$coefficients['sq__ft'] # extract the slope for the label positioning \n",
    "intercept_2 <- lm_2$coefficients['(Intercept)'] # extract the intercept for the label positioning\n",
    "\n",
    "abline( # add regression line\n",
    "    lm_2,\n",
    "    col = 'maroon1',\n",
    "    lw = 2\n",
    ")\n",
    "text(x = max(data$sq__ft)*.9,  # add label at the end of the regression line\n",
    "     y = slope_2 * max(data$sq__ft) + intercept_2, \n",
    "     \"Excluding 0\", \n",
    "     srt=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good checks to do: residual plot\n",
    "options(repr.plot.width=10, repr.plot.height=5) # this is not necessary in RStudio.\n",
    "\n",
    "# First calculate the residuals for both models\n",
    "residuals_1 <- resid(lm_1)\n",
    "residuals_2 <- resid(lm_2)\n",
    "\n",
    "# We should change the layout: we want now the two models' residuals next to each other.\n",
    "# We can use the mfrow argument in the par function, that is a general plotting function for changing standard\n",
    "# plotting parameters. This means that we should always remember to change it back to the default at the \n",
    "# end of the plotting.\n",
    "par(mfrow = c(1, 2))\n",
    "\n",
    "plot(x = data[, 'sq__ft'], \n",
    "     y = residuals_1, \n",
    "     col = rgb(0.1, 0.1, 0.1, .3), \n",
    "     pch = 20,\n",
    "     main = 'Including 0',\n",
    "     xlab = 'Squared feet',\n",
    "     ylab = 'Residuals',\n",
    "     bty = 'l'\n",
    "    )\n",
    "abline(h=0, lty=3) # plot a dotted horizontal line at 0\n",
    "\n",
    "plot(x = data[data$sq__ft > 0, 'sq__ft'], \n",
    "     y = residuals_2, \n",
    "     col = rgb(0.1, 0.1, 0.1, .3), \n",
    "     pch = 20,\n",
    "     main = 'Excluding 0',\n",
    "     xlab = 'Squared feet',\n",
    "     ylab = 'Residuals',\n",
    "     bty = 'l'\n",
    "    )\n",
    "abline(h=0, lty=3) # plot a dotted horizontal line at 0\n",
    "\n",
    "# Reset layout:\n",
    "par(mfrow = c(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The residuals do not seem to be exactly normally distributed.\n",
    "# Let's try to log transform the data (both x and y).\n",
    "\n",
    "options(repr.plot.width=5, repr.plot.height=5) # this is not necessary in RStudio.\n",
    "\n",
    "data_excluding0 = data[data$sq__ft > 0,]\n",
    "data_excluding0$log_price = log(data_excluding0$price)\n",
    "data_excluding0$log_sq__ft = log(data_excluding0$sq__ft)\n",
    "\n",
    "plot(x = data_excluding0$log_sq__ft, \n",
    "     y = data_excluding0$log_price, \n",
    "     col = rgb(0.1, 0.1, 0.1, .3), \n",
    "     pch = 20,\n",
    "     xlab = 'Log squared feet',\n",
    "     ylab = ' Log price',\n",
    "     bty = 'l',\n",
    "     log = 'xy'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although the data seem now much more suitable for linear regression, there seem to be an outlier:\n",
    "data_excluding0[data_excluding0$log_price < 10,]\n",
    "\n",
    "# Because a a price of 2000 also seems quite unrealistic, we can just exclude this property:\n",
    "data_excluding0 <- data_excluding0[data_excluding0$log_price > 10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try again, this time refitting the regression and checking the residuals:\n",
    "\n",
    "options(repr.plot.width=10, repr.plot.height=5) # this is not necessary in RStudio.\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "\n",
    "plot(x = data_excluding0$log_sq__ft, \n",
    "     y = data_excluding0$log_price, \n",
    "     col = rgb(0.1, 0.1, 0.1, .3), \n",
    "     pch = 20,\n",
    "     xlab = 'Log squared feet',\n",
    "     ylab = ' Log price',\n",
    "     bty = 'l',\n",
    "    )\n",
    "\n",
    "lm_3 <- lm(log_price ~ log_sq__ft, data_excluding0) # calculate the regression model\n",
    "residuals_3 <- resid(lm_3) # calculate residuals\n",
    "\n",
    "abline( # add regression line\n",
    "    lm_3,\n",
    "    col = 'maroon',\n",
    "    lw = 2\n",
    ")\n",
    "\n",
    "plot(x = data_excluding0$log_sq__ft, \n",
    "     y = residuals_3, \n",
    "     col = rgb(0.1, 0.1, 0.1, .3), \n",
    "     pch = 20,\n",
    "     xlab = 'Log squared feet',\n",
    "     ylab = 'Residuals',\n",
    "     bty = 'l'\n",
    "    )\n",
    "abline(h=0, lty=3) # plot a dotted horizontal line at 0\n",
    "\n",
    "par(mfrow = c(1, 1))\n",
    "\n",
    "# Much better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, we might want to now represent a third variable as a color code, e.g., the number of bathrooms:\n",
    "\n",
    "# And now let's plot a scatter plot where the color indicates the number of bathrooms:\n",
    "options(repr.plot.width=5, repr.plot.height=5) # this is not necessary in RStudio.\n",
    "\n",
    "plot(x = data_excluding0$log_sq__ft, \n",
    "     y = data_excluding0$log_price, \n",
    "     col = data_excluding0$baths, \n",
    "     pch = 20,\n",
    "     xlab = 'Log squared feet',\n",
    "     ylab = ' Log price',\n",
    "     bty = 'l',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The colors are not the best :D\n",
    "# Here some code to make it slightly more pleasing to the eyes:\n",
    "\n",
    "options(repr.plot.width=4, repr.plot.height=3) # this is not necessary in RStudio.\n",
    "\n",
    "# Let's first build a palette with number of colors the levels in he baths variable:\n",
    "colors <- c()\n",
    "gradient <- 0\n",
    "for (c in unique(data_excluding0$baths)) {\n",
    "    colors <- c(colors, rgb(gradient, .1, gradient, .3))\n",
    "    gradient <- gradient + .25\n",
    "}\n",
    "\n",
    "# And show the palette (just for fun):\n",
    "image(1:length(colors), \n",
    "      1, \n",
    "      as.matrix(1:length(colors)), \n",
    "      col=colors,\n",
    "      main = 'Number of bathrooms',\n",
    "      xlab=\"\", ylab = \"\", xaxt = \"n\", yaxt = \"n\", bty = \"n\")\n",
    "\n",
    "for (c in unique(data_excluding0$baths)) {\n",
    "    text(c, 1, c)\n",
    "}\n",
    "\n",
    "# Now we assign a color to each data point based on the palette we created:\n",
    "zcolor <- colors[data_excluding0$baths]\n",
    "\n",
    "# And now let's plot a scatter plot where the color indicates the number of bathrooms:\n",
    "options(repr.plot.width=5, repr.plot.height=5) # this is not necessary in RStudio.\n",
    "\n",
    "plot(x = data_excluding0$log_sq__ft, \n",
    "     y = data_excluding0$log_price, \n",
    "     col = zcolor, \n",
    "     pch = 20,\n",
    "     xlab = 'Log squared feet',\n",
    "     ylab = ' Log price',\n",
    "     bty = 'l',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Histograms & density lines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we saw in this scatteplot and regression exercise, is that it is important to inspect the **distribution** of the data, before we even try to attempt to fit models (as most statistical models assume the data to be distributed in certain ways...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=10, repr.plot.height=5) # this is not necessary in RStudio.\n",
    "\n",
    "hist(data$sq__ft,\n",
    "     main = '',\n",
    "     xlab = 'Squared feet',\n",
    "     breaks = 50\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot would have been already easy to **conclude** that:\n",
    "- there are a lot of data to be excluded, having 0 squared feet\n",
    "- the remaining data are positively skewed (therefore might be a good idea to log transform)\n",
    "\n",
    "You can also help the interpretation by plotting **mean** and **median** as vertical lines.\n",
    "\n",
    "When the median is lower than the mean, we are likely to have positively skewed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=5) # this is not necessary in RStudio.\n",
    "\n",
    "h <- hist( # assign it to variable to be able to access the frequencies\n",
    "    data$sq__ft,\n",
    "    main = '',\n",
    "    xlab = 'Squared feet',\n",
    "    breaks = 50\n",
    ")\n",
    "\n",
    "abline( # add the mean (calculated excluding the 0s)\n",
    "    v=mean(data[data$sq__ft > 0, 'sq__ft']),\n",
    "    col='blue3',\n",
    "    lty=3,\n",
    "    lw=3\n",
    "      )\n",
    "abline( # add the median (calculated excluding the 0s)\n",
    "    v=median(data[data$sq__ft > 0, 'sq__ft']),\n",
    "    col='blue3',\n",
    "    lty=2,\n",
    "    lw=3\n",
    "      )\n",
    "\n",
    "# To better position the legend, we can get the max frequency in the histogram:\n",
    "max_frequency <- max(h$counts)\n",
    "\n",
    "legend(\n",
    "    max(data$sq__ft)*.6, \n",
    "    max_frequency, \n",
    "    legend=c(\"Mean\", \"Median\"),\n",
    "    col='blue3',\n",
    "    lty=c(3, 2), \n",
    "    bg='white', \n",
    "    lw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better control the binning of the histograms, we should give a specific vector to the **breaks** argument, instead of just a number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=4, repr.plot.height=4) # this is not necessary in RStudio.\n",
    "\n",
    "# So, instead of:\n",
    "\n",
    "hist(\n",
    "    data$baths,\n",
    "    main = '',\n",
    "    xlab = 'Number of Bathrooms',\n",
    "    breaks = 6\n",
    ")\n",
    "\n",
    "# We do:\n",
    "\n",
    "hist(\n",
    "    data$baths,\n",
    "    main = '',\n",
    "    xlab = 'Number of Bathrooms',\n",
    "    breaks = seq(-.5, max(data$baths)+.5, 1)\n",
    ")\n",
    "\n",
    "# Not only in the top histogram there are 5 instead of the specified 6 bins, but it's unclear if the first bar\n",
    "# includes 0 or also 1s...\n",
    "# So always specify the breaks as a vector to increase interpretability!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the frequencies, we often want to plot **densities**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=10, repr.plot.height=5) # this is not necessary in RStudio.\n",
    "\n",
    "better_color <- rgb(.2, .4, .5, .3) # Già che ci siamo, we also change the color\n",
    "\n",
    "hist(\n",
    "    data_excluding0$price,\n",
    "    main = '',\n",
    "    xlab = 'Price',\n",
    "    breaks = 50,\n",
    "    freq = FALSE, # set this to false to get densities,\n",
    "    col = better_color,\n",
    "    border = better_color # you can change the color of the border to make it nicer...\n",
    ")\n",
    "\n",
    "# So that's good, but it's also super nice to add a density line on top of the histogram:\n",
    "density_price <- density(data_excluding0$price)\n",
    "\n",
    "better_color_denser <- rgb(.2, .4, .5, .8)\n",
    "\n",
    "lines(\n",
    "    density_price,\n",
    "    lw=3,\n",
    "    col= better_color_denser\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes we want to compare distributions with each other:\n",
    "col_1 <- rgb(.5, .3, .2, .3)\n",
    "col_2 <- rgb(.2, .5, .2, .3)\n",
    "\n",
    "breaks <- seq(min(data_excluding0$price), max(data_excluding0$price)*1.1, 50000)\n",
    "\n",
    "options(repr.plot.width=10, repr.plot.height=6) # this is not necessary in RStudio.\n",
    "\n",
    "hist(\n",
    "    data_excluding0$price[data_excluding0$beds <= 3],\n",
    "    main = '',\n",
    "    xlab = 'Price',\n",
    "    breaks = breaks,\n",
    "    freq = FALSE,\n",
    "    col = col_1,\n",
    "    border = col_1\n",
    ")\n",
    "\n",
    "hist(\n",
    "    data_excluding0$price[data_excluding0$beds > 3],\n",
    "    main = '',\n",
    "    xlab = 'Price',\n",
    "    breaks = breaks,\n",
    "    freq = FALSE,\n",
    "    col = col_2,\n",
    "    border = col_2,\n",
    "    add = TRUE # set this to true to overlap!\n",
    ")\n",
    "\n",
    "legend('topright', \n",
    "       legend = c(\"Up to 3\", \"More than 3\"), \n",
    "       col = c(col_1, col_2), \n",
    "       pch = c(15, 15))\n",
    "\n",
    "lines(\n",
    "    density(data_excluding0$price[data_excluding0$beds <= 3]),\n",
    "    lw=3,\n",
    "    col= col_1\n",
    "    )\n",
    "\n",
    "lines(\n",
    "    density(data_excluding0$price[data_excluding0$beds > 3]),\n",
    "    lw=3,\n",
    "    col= col_2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Boxplots & barplots with error bars:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots above are very good when we have continuous variables. Often though, we have continuous measurements for different experimental conditions, or groups of subjects, etc. With 2 or 3 levels of such variables, it's still relatively convenient to plot overlapping histograms or density lines alone. But when the number of levels increases, we might want to switch to **boxplots**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=6, repr.plot.height=5) # this is not necessary in RStudio.\n",
    "\n",
    "# Example:\n",
    "boxplot(\n",
    "    price ~ baths, \n",
    "    data = data_excluding0,\n",
    "    xlab = 'Number of bathrooms',\n",
    "    ylab = 'Price'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above, it is not necessarily clear how many observations we have per level of the categorical variable. To explore that, we can use **barplots**.\n",
    "\n",
    "Remember that **barplots** are a bit more stupid than **histograms** and **boxplots**. They often require us to calculate stuff first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many properties are there per level of bedrooms?\n",
    "table_beds <- table(data_excluding0$beds) # Calculate the y values\n",
    "\n",
    "barplot(\n",
    "    table_beds,\n",
    "    col = better_color,\n",
    "    border = better_color,\n",
    "    ylab = 'Counts',\n",
    "    xlab = 'Number of bedrooms'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we have a lot of categorical variables, it's nice to make it horizontal, \n",
    "# and order it by frequency:\n",
    "\n",
    "options(repr.plot.width=10, repr.plot.height=9) # this is not necessary in RStudio.\n",
    "\n",
    "table_city <- table(data_excluding0$city) # Calculate the y values\n",
    "table_city <- sort(table_city) # Order it by frequency\n",
    "\n",
    "par(las=1, # make the labels horizontal\n",
    "    mar=c(5.1,7.1,4.1,2.1)) # increase left margin\n",
    "\n",
    "barplot(\n",
    "    table_city,\n",
    "    col = better_color,\n",
    "    border = better_color,\n",
    "    xlab = 'Counts',\n",
    "    ylab = '',\n",
    "    horiz = TRUE,\n",
    "    cex.names = .6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**barplots** are also very flexible. Another important thing we might want to do is to for example compare the mean of X aggregated by either 1 or two independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data retrieved from https://www.kaggle.com/ronitf/heart-disease-uci\n",
    "data <- read.csv('~/git/RcourseSpring2019/data/heart.csv')\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One grouping variable, confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean cholestoral per sex(1 = male; 0 = female), with CONFIDENCE INTERVALS:\n",
    "\n",
    "# 1. First calculate the grouped mean, steandard deviation, and number of observations\n",
    "grouped_mean <- aggregate(\n",
    "    formula = chol ~ sex,\n",
    "    data = data,\n",
    "    FUN = mean\n",
    ")\n",
    "\n",
    "grouped_sd <- aggregate(\n",
    "    formula = chol ~ sex,\n",
    "    data = data,\n",
    "    FUN = sd\n",
    ")\n",
    "\n",
    "grouped_n <- aggregate(\n",
    "    formula = chol ~ sex,\n",
    "    data = data,\n",
    "    FUN = length\n",
    ")\n",
    "\n",
    "# 2. Then calculate the standard error of the grouped means:\n",
    "\n",
    "# It is the standard deviation of the vector sampling distribution. \n",
    "# Calculated as the SD divided by the square root of the sample size. \n",
    "# By construction, SE is smaller than SD. With a very big sample size, SE tends toward 0.\n",
    "\n",
    "grouped_se <- grouped_sd$chol / sqrt(grouped_n$chol)\n",
    "grouped_se\n",
    "\n",
    "# 3. Then calculate the confidence intervals:\n",
    "\n",
    "# This interval is defined so that there is a specified probability that a value lies within it. \n",
    "# It is calculated as t * SE. Where t is the value of the Student’s t-distribution for a specific alpha. \n",
    "# Its value is often rounded to 1.96 (its value with a big sample size). \n",
    "# If the sample size is huge or the distribution not normal, it is better to calculate the CI using the bootstrap method.\n",
    "\n",
    "alpha <- 0.05 # Significance level\n",
    "t <- qt((1-alpha)/2 + .5, grouped_n$chol - 1)   # tend to 1.96 if sample size is big enough\n",
    "grouped_ci <- t*grouped_se\n",
    "grouped_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=5, repr.plot.height=5) # this is not necessary in RStudio.\n",
    "\n",
    "b <- barplot(\n",
    "    height = grouped_mean$chol,\n",
    "    names.arg = grouped_mean$sex,\n",
    "    col = better_color,\n",
    "    border = better_color,\n",
    "    ylim = c(0, max(grouped_mean$chol+grouped_ci)),\n",
    "    xlab = 'Sex',\n",
    "    ylab = 'Serum cholestoral in mg/dl'\n",
    "       )\n",
    "\n",
    "segments(\n",
    "    x0 = b, \n",
    "    x1 = b, \n",
    "    y0 = grouped_mean$chol-grouped_ci, \n",
    "    y1 = grouped_mean$chol+grouped_ci, \n",
    "    lwd = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One grouping variable, Standard errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean resting maximum heart rate per age, with STANDARD ERRORS:\n",
    "\n",
    "# 1. First calculate the grouped mean, steandard deviation, and number of observations\n",
    "grouped_mean <- aggregate(\n",
    "    formula = thalach ~ age,\n",
    "    data = data,\n",
    "    FUN = mean\n",
    ")\n",
    "\n",
    "grouped_sd <- aggregate(\n",
    "    formula = thalach ~ age,\n",
    "    data = data,\n",
    "    FUN = sd\n",
    ")\n",
    "\n",
    "grouped_n <- aggregate(\n",
    "    formula = thalach ~ age,\n",
    "    data = data,\n",
    "    FUN = length\n",
    ")\n",
    "\n",
    "# 2. Then calculate the standard error of the grouped means:\n",
    "\n",
    "grouped_se <- grouped_sd$thalach / sqrt(grouped_n$thalach)\n",
    "\n",
    "# Eliminate the NA:\n",
    "grouped_mean <- grouped_mean[!is.na(grouped_se),]\n",
    "grouped_se <- grouped_se[!is.na(grouped_se)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=9, repr.plot.height=5) # this is not necessary in RStudio.\n",
    "\n",
    "b <- barplot(\n",
    "    height = grouped_mean$thalach,\n",
    "    names.arg = grouped_mean$age,\n",
    "    col = better_color,\n",
    "    border = better_color,\n",
    "    ylim = c(0, max(grouped_mean$thalach + grouped_se)),\n",
    "    xlab = 'Age',\n",
    "    ylab = 'Maximum heart rate '\n",
    "       )\n",
    "\n",
    "segments(\n",
    "    x0 = b, \n",
    "    x1 = b, \n",
    "    y0 = grouped_mean$thalach - grouped_se, \n",
    "    y1 = grouped_mean$thalach + grouped_se, \n",
    "    lwd = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two grouping variables, confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First calculate the grouped mean, steandard deviation, and number of observations\n",
    "grouped_mean <- aggregate(\n",
    "    formula = trestbps ~ sex + cp,\n",
    "    data = data,\n",
    "    FUN = mean\n",
    ")\n",
    "\n",
    "grouped_sd <- aggregate(\n",
    "    formula = trestbps ~ sex + cp,\n",
    "    data = data,\n",
    "    FUN = sd\n",
    ")\n",
    "\n",
    "grouped_n <- aggregate(\n",
    "    formula = trestbps ~ sex + cp,\n",
    "    data = data,\n",
    "    FUN = length\n",
    ")\n",
    "\n",
    "head(grouped_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To feed into the barplot function, we need a table-like object, with, e.g, age as rows and sex as columns.\n",
    "# We can thus use the reshape2 package for this purpose and transform our data to wide format using the function acast:\n",
    "\n",
    "grouped_mean_wide <- acast(\n",
    "    data = grouped_mean, \n",
    "    formula = sex ~ cp\n",
    ")\n",
    "\n",
    "grouped_sd_wide <- acast(\n",
    "    data = grouped_sd, \n",
    "    formula = sex ~ cp\n",
    ")\n",
    "\n",
    "grouped_n_wide <- acast(\n",
    "    data = grouped_n, \n",
    "    formula = sex ~ cp\n",
    ")\n",
    "\n",
    "grouped_mean_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Then calculate the standard error of the grouped means:\n",
    "grouped_se_wide <- grouped_sd_wide / sqrt(grouped_n_wide)\n",
    "\n",
    "# 3. Then calculate the confidence intervals:\n",
    "\n",
    "alpha <- 0.05 # Significance level\n",
    "t <- qt((1-alpha)/2 + .5, grouped_n_wide - 1)   # tend to 1.96 if sample size is big enough\n",
    "grouped_ci_wide <- t*grouped_se_wide\n",
    "\n",
    "grouped_ci_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate NAs:\n",
    "which_NAs <- apply(\n",
    "    X = is.na(grouped_ci_wide),\n",
    "    MARGIN = 2,\n",
    "    FUN = sum\n",
    ")\n",
    "\n",
    "grouped_mean_wide <- grouped_mean_wide[,which_NAs == 0]\n",
    "grouped_ci_wide <- grouped_ci_wide[,which_NAs == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are ready to plot:\n",
    "b <- barplot(\n",
    "    height = grouped_mean_wide,\n",
    "    names.arg = c('typical angina', 'atypical angina', 'non-anginal pain', 'asymptomatic'),\n",
    "    ylab = 'Resting blood pressure',\n",
    "    xlab = 'Chest pain type',\n",
    "    col = c('pink3', 'lightblue3'),\n",
    "    beside = TRUE, \n",
    "    legend.text = TRUE,\n",
    "    ylim = c(0, max(grouped_mean_wide + grouped_ci_wide))\n",
    ")\n",
    "\n",
    "segments(\n",
    "    x0 = b,\n",
    "    x1 = b,\n",
    "    y0 = grouped_mean_wide - grouped_ci_wide,\n",
    "    y1 = grouped_mean_wide + grouped_ci_wide,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two grouping variables, standard errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First calculate the grouped mean, steandard deviation, and number of observations\n",
    "grouped_mean <- aggregate(\n",
    "    formula = chol ~ sex + age,\n",
    "    data = data,\n",
    "    FUN = mean\n",
    ")\n",
    "\n",
    "grouped_sd <- aggregate(\n",
    "    formula = chol ~ sex + age,\n",
    "    data = data,\n",
    "    FUN = sd\n",
    ")\n",
    "\n",
    "grouped_n <- aggregate(\n",
    "    formula = chol ~ sex + age,\n",
    "    data = data,\n",
    "    FUN = length\n",
    ")\n",
    "\n",
    "head(grouped_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_mean_wide <- acast(\n",
    "    data = grouped_mean, \n",
    "    formula = sex ~ age\n",
    ")\n",
    "\n",
    "grouped_sd_wide <- acast(\n",
    "    data = grouped_sd, \n",
    "    formula = sex ~ age\n",
    ")\n",
    "\n",
    "grouped_n_wide <- acast(\n",
    "    data = grouped_n, \n",
    "    formula = sex ~ age\n",
    ")\n",
    "\n",
    "grouped_mean_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Then calculate the standard error of the grouped means:\n",
    "grouped_se_wide <- grouped_sd_wide / sqrt(grouped_n_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate NAs:\n",
    "which_NAs <- apply(\n",
    "    X = is.na(grouped_se_wide),\n",
    "    MARGIN = 2,\n",
    "    FUN = sum\n",
    ")\n",
    "\n",
    "grouped_mean_wide <- grouped_mean_wide[,which_NAs == 0]\n",
    "grouped_se_wide <- grouped_se_wide[,which_NAs == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are ready to plot:\n",
    "b <- barplot(\n",
    "    height = grouped_mean_wide,\n",
    "    ylab = 'Serum cholestoral in mg/dl',\n",
    "    xlab = 'Age',\n",
    "    col = c('pink3', 'lightblue3'),\n",
    "    beside = TRUE, \n",
    "    legend.text = TRUE,\n",
    "    ylim = c(0, max(grouped_mean_wide + grouped_se_wide))\n",
    ")\n",
    "\n",
    "segments(\n",
    "    x0 = b,\n",
    "    x1 = b,\n",
    "    y0 = grouped_mean_wide - grouped_se_wide,\n",
    "    y1 = grouped_mean_wide + grouped_se_wide,\n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
